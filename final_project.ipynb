{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "**Group HOMEWORK**. This final project can be collaborative. The maximum members of a group is 2. You can also work by yourself. Please respect the academic integrity. **Remember: if you get caught on cheating, you get F.**\n",
    "\n",
    "## A Introduction to the competition\n",
    "\n",
    "<img src=\"news-sexisme-EN.jpg\" alt=\"drawing\" width=\"380\"/>\n",
    "\n",
    "Sexism is a growing problem online. It can inflict harm on women who are targeted, make online spaces inaccessible and unwelcoming, and perpetuate social asymmetries and injustices. Automated tools are now widely deployed to find, and assess sexist content at scale but most only give classifications for generic, high-level categories, with no further explanation. Flagging what is sexist content and also explaining why it is sexist improves interpretability, trust and understanding of the decisions that automated tools use, empowering both users and moderators.\n",
    "\n",
    "This project is based on SemEval 2023 - Task 10 - Explainable Detection of Online Sexism (EDOS). [Here](https://codalab.lisn.upsaclay.fr/competitions/7124#learn_the_details-overview) you can find a detailed introduction to this task.\n",
    "\n",
    "You only need to complete **TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist**. To cut down training time, we only use a subset of the original dataset (5k out of 20k). The dataset can be found in the same folder. \n",
    "\n",
    "Different from our previous homework, this competition gives you great flexibility (and very few hints), you can determine: \n",
    "-  how to preprocess the input text (e.g., remove emoji, remove stopwords, text lemmatization and stemming, etc.);\n",
    "-  which method to use to encode text features (e.g., TF-IDF, N-grams, Word2vec, GloVe, Part-of-Speech (POS), etc.);\n",
    "-  which model to use.\n",
    "\n",
    "## Requirements\n",
    "-  **Input**: the text for each instance.\n",
    "-  **Output**: the binary label for each instance.\n",
    "-  **Feature engineering**: use at least 2 different methods to extract features and encode text into numerical values.\n",
    "-  **Model selection**: implement with at least 3 different models and compare their performance.\n",
    "-  **Evaluation**: create a dataframe with rows indicating feature+model and columns indicating Precision, Accuracy and F1-score (using weighted average). Your results should have at least 6 rows (2 feature engineering methods x 3 models). Report best performance with (1) your feature engineering method, and (2) the model you choose. \n",
    "- **Format**: add explainations for each step (you can add markdown cells). At the end of the report, write a summary and answer the following questions: \n",
    "    - What preprocessing steps do you follow?\n",
    "    - How do you select the features from the inputs? \n",
    "    - Which model you use and what is the structure of your model?\n",
    "    - How do you train your model?\n",
    "    - What is the performance of your best model?\n",
    "    - What other models or feature engineering methods would you like to implement in the future?\n",
    "- **Two Rules**, violations will result in 0 points in the grade: \n",
    "    - Not allowed to use test set in the training: You CANNOT use any of the instances from test set in the training process. \n",
    "    - Not allowed to use code from generative AI (e.g., ChatGPT). \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The performance should be only evaluated on the test set (a total of 1086 instances). Please split original dataset into train set and test set. The test set should NEVER be used in the training process. The evaluation metric is a combination of precision, recall, and f1-score (use `classification_report` in sklearn). \n",
    "\n",
    "The total points are 10.0. Each team will compete with other teams in the class on their best performance. Points will be deducted if not following the requirements above.\n",
    "\n",
    "If ALL the requirements are met:\n",
    "- Top 25\\% teams: 10.0 points.\n",
    "- Top 25\\% - 50\\% teams: 8.5 points.\n",
    "- Top 50\\% - 75\\% teams: 7.0 points.\n",
    "- Top 75\\% - 100\\% teams: 6.0 points.\n",
    "\n",
    "## Submission\n",
    "Similar as homework, submit both a PDF and .ipynb version of the report. \n",
    "\n",
    "The report should include: (a)code, (b)outputs, (c)explainations for each step, and (d)summary (you can add markdown cells). \n",
    "\n",
    "The due date is **December 8, Friday by 11:59pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b7caf28-1c77-4f87-8a62-7f3a7f79e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Then, she's a keeper. ðŸ˜‰</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is like the Metallica video where the poo...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woman?</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bet she wished she had a gun</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unlicensed day care worker reportedly tells co...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[USER] Leg day is easy. Hot girls who wear min...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't know if you should avoid this one or e...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I get a new pussy every other week or whenever...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I agree with that but at the same time I know ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label  split\n",
       "0  In Nigeria, if you rape a woman, the men rape ...  not sexist  train\n",
       "1                            Then, she's a keeper. ðŸ˜‰  not sexist  train\n",
       "2  This is like the Metallica video where the poo...  not sexist  train\n",
       "3                                             woman?  not sexist  train\n",
       "4                     I bet she wished she had a gun  not sexist  train\n",
       "5  Unlicensed day care worker reportedly tells co...  not sexist  train\n",
       "6  [USER] Leg day is easy. Hot girls who wear min...      sexist  train\n",
       "7  I don't know if you should avoid this one or e...  not sexist  train\n",
       "8  I get a new pussy every other week or whenever...      sexist  train\n",
       "9  I agree with that but at the same time I know ...      sexist  train"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv('edos_labelled_data.csv')\n",
    "df.drop(['rewire_id'], axis=1, inplace=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48a1947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate the final report in a dictionary format\n",
    "def put_in_final_dict(cls_rep, final_report_dict, name):\n",
    "    if(final_report_dict == {}):\n",
    "        final_report_dict[\"Feature+Model\"] = [name]\n",
    "        final_report_dict[\"Sexist Precision\"] = [cls_rep[\"1\"][\"precision\"]]\n",
    "        final_report_dict[\"Sexist Recall\"] = [cls_rep[\"1\"][\"recall\"]]\n",
    "        final_report_dict[\"Sexist F1-Score\"] = [cls_rep[\"1\"][\"f1-score\"]]\n",
    "        final_report_dict[\"Non-Sexist Precision\"] = [cls_rep[\"0\"][\"precision\"]]\n",
    "        final_report_dict[\"Non-Sexist Recall\"] = [cls_rep[\"0\"][\"recall\"]]\n",
    "        final_report_dict[\"Non-Sexist F1-Score\"] = [cls_rep[\"0\"][\"f1-score\"]]\n",
    "        final_report_dict[\"Weighted Average Precision\"] = [cls_rep[\"weighted avg\"][\"precision\"]]\n",
    "        final_report_dict[\"Weighted Average Recall\"] = [cls_rep[\"weighted avg\"][\"recall\"]]\n",
    "        final_report_dict[\"Weighted Average F1-Score\"] = [cls_rep[\"weighted avg\"][\"recall\"]]\n",
    "    else:\n",
    "        final_report_dict[\"Feature+Model\"].append(name)\n",
    "        final_report_dict[\"Non-Sexist Precision\"].append(cls_rep[\"0\"][\"precision\"])\n",
    "        final_report_dict[\"Non-Sexist Recall\"].append(cls_rep[\"0\"][\"recall\"])\n",
    "        final_report_dict[\"Non-Sexist F1-Score\"].append(cls_rep[\"0\"][\"f1-score\"])\n",
    "        final_report_dict[\"Sexist Precision\"].append(cls_rep[\"1\"][\"precision\"])\n",
    "        final_report_dict[\"Sexist Recall\"].append(cls_rep[\"1\"][\"recall\"])\n",
    "        final_report_dict[\"Sexist F1-Score\"].append(cls_rep[\"1\"][\"f1-score\"])\n",
    "        final_report_dict[\"Weighted Average Precision\"].append(cls_rep[\"weighted avg\"][\"precision\"])\n",
    "        final_report_dict[\"Weighted Average Recall\"].append(cls_rep[\"weighted avg\"][\"recall\"])\n",
    "        final_report_dict[\"Weighted Average F1-Score\"].append(cls_rep[\"weighted avg\"][\"recall\"])\n",
    "    return final_report_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c68b14e",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "\n",
    "In the data cleanup step, we performed several operations to prepare our data for the machine learning model:\n",
    "\n",
    "1. **Tokenization**: We broke down the text into individual words, or \"tokens\". This is a common first step in text analysis.\n",
    "\n",
    "2. **Lemmatization**: We reduced words to their base or root form (e.g., \"running\" to \"run\"). This helps in consolidating different variations of the same word.\n",
    "\n",
    "3. **Removing Out-of-Vocabulary Things**: We removed emojis, URLs, and other things that are not words.\n",
    "\n",
    "4. **Removing Stop Words**: We removed \"stop words\", which are common words like \"is\", \"the\", and \"a\". These words don't provide meaningful information for the analysis.\n",
    "\n",
    "These steps helped in reducing noise and dimensionality in our data, and made it suitable for training our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75edf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to remove contractions from the text\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"don\\'t\", \"do not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce529c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "        \"]+\", flags=re.UNICODE)\n",
    "bracket_pattern = re.compile(\"\\[[A-Z]+\\]\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "df['word_tokens'] = ''\n",
    "for i in range(len(df)):\n",
    "    if \"sexist\" == df.loc[i,'label']:\n",
    "        df.loc[i,'label'] = \"1\"\n",
    "    else:\n",
    "        df.loc[i,'label'] = \"0\"\n",
    "    df.loc[i,'text'] = emoji_pattern.sub(r'', df.loc[i,'text'])\n",
    "    df.loc[i,'text'] = bracket_pattern.sub(r'', df.loc[i,'text'])\n",
    "    df.loc[i,'text'] = df.loc[i,'text'].lower()\n",
    "    df.loc[i,'text'] = decontracted(df.loc[i,'text'])\n",
    "    word_tokens = tokenizer.tokenize(df.loc[i,'text'])\n",
    "    lemmatized_tokens = [wordnet_lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "    filtered_sentence = [w for w in lemmatized_tokens if not w in stop_words and not w.isdigit()]\n",
    "    df.loc[i,'word_tokens'] = \" \".join(filtered_sentence)\n",
    "    \n",
    "#splitting the data into train and test\n",
    "df_train = df[df['split'] != 'test']\n",
    "df_test = df[df['split'] == 'test']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69935d83",
   "metadata": {},
   "source": [
    "# Feature Extraction and Model Training\n",
    "\n",
    "In this project, we used Count Vectorization to transform our text data into a format that can be used by machine learning models. Count Vectorization converts a collection of text documents into a matrix of token counts. This is a simple and effective way to represent text data numerically.\n",
    "\n",
    "After transforming our text data into a document-term matrix using Count Vectorization, we trained several machine learning models:\n",
    "\n",
    "1. **Logistic Regression**: This is a simple yet powerful linear model that is widely used for classification problems. It's particularly good at handling binary classification problems.\n",
    "\n",
    "2. **Multinomial Naive Bayes**: This is a probabilistic classifier that is highly effective for text data. It's based on applying Bayes' theorem with strong independence assumptions between the features.\n",
    "\n",
    "3. **MLPClassifier**: This stands for Multi-Layer Perceptron Classifier. It's a type of neural network that consists of at least three layers of nodes and can handle complex data.\n",
    "\n",
    "Each of these models was trained on our document-term matrix and then used to make predictions on unseen data. The performance of each model was evaluated using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88ecf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#vectorizing the data\n",
    "vectorize = CountVectorizer()\n",
    "vectorize.fit(df_train['word_tokens'])\n",
    "X_train = vectorize.transform(df_train['word_tokens'])\n",
    "X_test = vectorize.transform(df_test['word_tokens'])\n",
    "y_train = df_train['label']\n",
    "y_test = df_test['label']\n",
    "final_report_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bfbed",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69c05403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  82.96500920810314\n",
      "Best C:  0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Logistic Regression with Count Vectorizer\n",
    "best_score = 0\n",
    "best_c = 0\n",
    "for i in range(1,100):\n",
    "    i = i/100\n",
    "    model = LogisticRegression(penalty='l1', C=i, solver='liblinear', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_c = i\n",
    "print(\"Best score: \", best_score*100)\n",
    "print(\"Best C: \", best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f168331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[757  32]\n",
      " [153 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       789\n",
      "           1       0.82      0.48      0.61       297\n",
      "\n",
      "    accuracy                           0.83      1086\n",
      "   macro avg       0.83      0.72      0.75      1086\n",
      "weighted avg       0.83      0.83      0.81      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#Using the best C value to train the model\n",
    "model = LogisticRegression(penalty='l1', C=best_c, solver='liblinear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_LR))\n",
    "cls_rep = classification_report(y_test, y_pred_LR)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_LR, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"CountVectorizer+LogisticRegression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9df35",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a041acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  77.53222836095765\n",
      "Best alpha:  0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Multinomial Naive Bayes with Count Vectorizer\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for i in range(1,100):\n",
    "    i = i/100\n",
    "    model = MultinomialNB(alpha=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = i\n",
    "print(\"Best score: \", best_score*100)\n",
    "print(\"Best alpha: \", best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd580ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[716  73]\n",
      " [171 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85       789\n",
      "           1       0.63      0.42      0.51       297\n",
      "\n",
      "    accuracy                           0.78      1086\n",
      "   macro avg       0.72      0.67      0.68      1086\n",
      "weighted avg       0.76      0.78      0.76      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the best alpha value to train the model\n",
    "model = MultinomialNB(alpha=best_alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_MNB = model.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_MNB))\n",
    "cls_rep = classification_report(y_test, y_pred_MNB)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_MNB, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"CountVectorizer+MultinomialNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583629e",
   "metadata": {},
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87506214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[724  65]\n",
      " [136 161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       789\n",
      "           1       0.71      0.54      0.62       297\n",
      "\n",
      "    accuracy                           0.81      1086\n",
      "   macro avg       0.78      0.73      0.75      1086\n",
      "weighted avg       0.81      0.81      0.81      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#MLP Classifier with Count Vectorizer\n",
    "activation = 'tanh'\n",
    "solver = 'adam'\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "batch_size = 2**5\n",
    "hidden_layer_sizes = (7,7,7)\n",
    "\n",
    "## For finding best alpha, Code commneted out becuae takes too long to run everytime\n",
    "# for i in range(1,100):\n",
    "#     i = i/100\n",
    "#     clf = MLPClassifier(activation=activation, solver=solver, alpha=i, hidden_layer_sizes=hidden_layer_sizes, random_state=1, max_iter=1000, batch_size=batch_size, shuffle=True, verbose=False, early_stopping=True, learning_rate_init=0.0008)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     score = clf.score(X_test, y_test)\n",
    "#     # print(\"Score for \",i, \": \", score*100)\n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         best_alpha = i\n",
    "# print(\"Best score: \", best_score*100)\n",
    "# print(\"Best alpha: \", best_alpha)\n",
    "best_alpha = 0.47\n",
    "\n",
    "#Using the best alpha value to train the model\n",
    "clf = MLPClassifier(activation=activation, solver=solver, alpha=best_alpha, hidden_layer_sizes=hidden_layer_sizes, random_state=1, max_iter=1000, batch_size=batch_size, shuffle=True, verbose=False, early_stopping=True, learning_rate_init=0.0008)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_MLP = clf.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_MLP))\n",
    "cls_rep = classification_report(y_test, y_pred_MLP)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_MLP, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"CountVectorizer+MLPClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010ba3d2",
   "metadata": {},
   "source": [
    "# Feature Extraction with TF-IDF\n",
    "\n",
    "In this project, we used TF-IDF (Term Frequency-Inverse Document Frequency) to transform our text data into a format that can be used by machine learning models. \n",
    "\n",
    "TF-IDF is a numerical statistic that reflects how important a word is to a document in a collection or corpus. It is often used in information retrieval and text mining. The TF-IDF value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general.\n",
    "\n",
    "After transforming our text data into a matrix of TF-IDF features, we trained several machine learning models. The models were able to use these features to learn patterns in the data and make predictions on unseen data.\n",
    "\n",
    "1. **Logistic Regression**: This is a simple yet powerful linear model that is widely used for classification problems. It's particularly good at handling binary classification problems.\n",
    "\n",
    "2. **Multinomial Naive Bayes**: This is a probabilistic classifier that is highly effective for text data. It's based on applying Bayes' theorem with strong independence assumptions between the features.\n",
    "\n",
    "3. **MLPClassifier**: This stands for Multi-Layer Perceptron Classifier. It's a type of neural network that consists of at least three layers of nodes and can handle complex data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e1d5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#TF-IDF Vectorizer\n",
    "vectorize = TfidfVectorizer()\n",
    "vectorize.fit(df_train['word_tokens'])\n",
    "X_train = vectorize.transform(df_train['word_tokens'])\n",
    "X_test = vectorize.transform(df_test['word_tokens'])\n",
    "y_train = df_train['label']\n",
    "y_test = df_test['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be82322",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16b98324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  80.38674033149171\n",
      "Best C:  0.77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Logistic Regression with TF-IDF Vectorizer\n",
    "best_score = 0\n",
    "best_c = 0\n",
    "for i in range(1,100):\n",
    "    i = i/100\n",
    "    model = LogisticRegression(penalty='l1', C=i, solver='liblinear', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_c = i\n",
    "print(\"Best score: \", best_score*100)\n",
    "print(\"Best C: \", best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fa0846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[760  29]\n",
      " [184 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       789\n",
      "           1       0.80      0.38      0.51       297\n",
      "\n",
      "    accuracy                           0.80      1086\n",
      "   macro avg       0.80      0.67      0.70      1086\n",
      "weighted avg       0.80      0.80      0.78      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the best C value to train the model\n",
    "model = LogisticRegression(penalty='l1', C=best_c, solver='liblinear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_LR))\n",
    "cls_rep = classification_report(y_test, y_pred_LR)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_LR, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"TfidfVectorizer+LogisticRegression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7cd21",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "719c7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  75.87476979742172\n",
      "Best alpha:  0.35\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes with TF-IDF Vectorizer\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "for i in range(1,100):\n",
    "    i = i/100\n",
    "    model = MultinomialNB(alpha=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = i\n",
    "print(\"Best score: \", best_score*100)\n",
    "print(\"Best alpha: \", best_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be016d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[773  16]\n",
      " [246  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       789\n",
      "           1       0.76      0.17      0.28       297\n",
      "\n",
      "    accuracy                           0.76      1086\n",
      "   macro avg       0.76      0.58      0.57      1086\n",
      "weighted avg       0.76      0.76      0.70      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using the best alpha value to train the model\n",
    "model = MultinomialNB(alpha=best_alpha)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_MNB = model.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_MNB))\n",
    "cls_rep = classification_report(y_test, y_pred_MNB)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_MNB, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"TfidfVectorizer+MultinomialNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5842eb",
   "metadata": {},
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6737d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[686 103]\n",
      " [129 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       789\n",
      "           1       0.62      0.57      0.59       297\n",
      "\n",
      "    accuracy                           0.79      1086\n",
      "   macro avg       0.73      0.72      0.72      1086\n",
      "weighted avg       0.78      0.79      0.78      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MLP Classifier with TF-IDF Vectorizer\n",
    "activation = 'relu'\n",
    "solver = 'adam'\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "batch_size = 2**3\n",
    "hidden_layer_sizes = (2,4,4)\n",
    "\n",
    "## Found after a long and extremly slow process, code removed becuase it would take 10+ minutes to run\n",
    "# for i in range(1,100):\n",
    "#     i = i/100\n",
    "#     clf = MLPClassifier(activation=activation, solver=solver, alpha=best_alpha, hidden_layer_sizes=hidden_layer_sizes, random_state=1, max_iter=5000, batch_size=batch_size, shuffle=True, verbose=False, early_stopping=True, learning_rate_init=0.002)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     score = clf.score(X_test, y_test)\n",
    "#     # print(\"Score for \",i, \": \", score*100)\n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         best_alpha = i\n",
    "# print(best_alpha)\n",
    "# print(best_score)\n",
    "best_alpha = 0.0411002\n",
    "\n",
    "#Using the best alpha value to train the model\n",
    "clf = MLPClassifier(activation=activation, solver=solver, alpha=best_alpha, hidden_layer_sizes=hidden_layer_sizes, random_state=1, max_iter=1000, batch_size=batch_size, shuffle=True, verbose=False, early_stopping=True, learning_rate_init=0.002)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_MLP = clf.predict(X_test)\n",
    "\n",
    "#Printing the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_MLP))\n",
    "cls_rep = classification_report(y_test, y_pred_MLP)\n",
    "print(cls_rep)\n",
    "\n",
    "#Adding the results to the final report\n",
    "cls_rep = (classification_report(y_test, y_pred_MLP, output_dict=True))\n",
    "final_report_dict = put_in_final_dict(cls_rep, final_report_dict, \"TfidfVectorizer+MLPClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39e9e3",
   "metadata": {},
   "source": [
    "# Creating the Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c977e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature+Model</th>\n",
       "      <th>Sexist Precision</th>\n",
       "      <th>Sexist Recall</th>\n",
       "      <th>Sexist F1-Score</th>\n",
       "      <th>Non-Sexist Precision</th>\n",
       "      <th>Non-Sexist Recall</th>\n",
       "      <th>Non-Sexist F1-Score</th>\n",
       "      <th>Weighted Average Precision</th>\n",
       "      <th>Weighted Average Recall</th>\n",
       "      <th>Weighted Average F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer+LogisticRegression</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.608879</td>\n",
       "      <td>0.831868</td>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.891112</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.829650</td>\n",
       "      <td>0.829650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CountVectorizer+MLPClassifier</td>\n",
       "      <td>0.712389</td>\n",
       "      <td>0.542088</td>\n",
       "      <td>0.615679</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>0.917617</td>\n",
       "      <td>0.878108</td>\n",
       "      <td>0.806453</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>0.814917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfidfVectorizer+LogisticRegression</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.380471</td>\n",
       "      <td>0.514806</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.963245</td>\n",
       "      <td>0.877092</td>\n",
       "      <td>0.802539</td>\n",
       "      <td>0.803867</td>\n",
       "      <td>0.803867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TfidfVectorizer+MLPClassifier</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.841718</td>\n",
       "      <td>0.869455</td>\n",
       "      <td>0.855362</td>\n",
       "      <td>0.781062</td>\n",
       "      <td>0.786372</td>\n",
       "      <td>0.786372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CountVectorizer+MultinomialNB</td>\n",
       "      <td>0.633166</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>0.807215</td>\n",
       "      <td>0.907478</td>\n",
       "      <td>0.854415</td>\n",
       "      <td>0.759616</td>\n",
       "      <td>0.775322</td>\n",
       "      <td>0.775322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer+MultinomialNB</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.280220</td>\n",
       "      <td>0.758587</td>\n",
       "      <td>0.979721</td>\n",
       "      <td>0.855088</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.758748</td>\n",
       "      <td>0.758748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature+Model  Sexist Precision  Sexist Recall  \\\n",
       "0  CountVectorizer+LogisticRegression          0.818182       0.484848   \n",
       "2       CountVectorizer+MLPClassifier          0.712389       0.542088   \n",
       "3  TfidfVectorizer+LogisticRegression          0.795775       0.380471   \n",
       "5       TfidfVectorizer+MLPClassifier          0.619926       0.565657   \n",
       "1       CountVectorizer+MultinomialNB          0.633166       0.424242   \n",
       "4       TfidfVectorizer+MultinomialNB          0.761194       0.171717   \n",
       "\n",
       "   Sexist F1-Score  Non-Sexist Precision  Non-Sexist Recall  \\\n",
       "0         0.608879              0.831868           0.959442   \n",
       "2         0.615679              0.841860           0.917617   \n",
       "3         0.514806              0.805085           0.963245   \n",
       "5         0.591549              0.841718           0.869455   \n",
       "1         0.508065              0.807215           0.907478   \n",
       "4         0.280220              0.758587           0.979721   \n",
       "\n",
       "   Non-Sexist F1-Score  Weighted Average Precision  Weighted Average Recall  \\\n",
       "0             0.891112                    0.828125                 0.829650   \n",
       "2             0.878108                    0.806453                 0.814917   \n",
       "3             0.877092                    0.802539                 0.803867   \n",
       "5             0.855362                    0.781062                 0.786372   \n",
       "1             0.854415                    0.759616                 0.775322   \n",
       "4             0.855088                    0.759300                 0.758748   \n",
       "\n",
       "   Weighted Average F1-Score  \n",
       "0                   0.829650  \n",
       "2                   0.814917  \n",
       "3                   0.803867  \n",
       "5                   0.786372  \n",
       "1                   0.775322  \n",
       "4                   0.758748  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Puting the final report in a dataframe and sorting it by the weighted average F1-Score\n",
    "df_final_report = pd.DataFrame(final_report_dict)\n",
    "df_final_report.sort_values(by=['Weighted Average F1-Score'], inplace=True, ascending=False)\n",
    "df_final_report.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
